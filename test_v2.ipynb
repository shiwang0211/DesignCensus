{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://designcensus.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "## 1. [Data Preprocessing](#1.0)\n",
    "## 2. [Barplots](#2.0)\n",
    "- [Distribution Table for each column](#2.1)\n",
    "- [All/AIGA Count Plot for each column](#2.2)\n",
    "- [Salary vs. Column plots](#2.3)\n",
    "\n",
    "## 3. [Heatmaps](#3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.0'></a>\n",
    "# Part I, Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('DesignCensus2017_Data.csv', encoding = 'utf8')\n",
    "print('There a a total of ' + str(len(df.columns)) + ' columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column name dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "for col in df.columns:\n",
    "    index, desc = col.split(' --')\n",
    "    col_dict['V_' + str(index)] = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_with_column_names(df, col_dict):\n",
    "    df_v2 = df.copy()\n",
    "    df_v2.columns = [col_dict[col] for col in df_v2.columns]\n",
    "    return df_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify columns (continuous, categorical, multiple pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = map(lambda x : 'V_' + str(x+1), list(range(len(df.columns)))) \n",
    "df['V_36'] = df['V_36'].astype(np.object) # ZIPCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "continous_cols = ['V_18', 'V_37']\n",
    "pipe_col = ['V_2', 'V_3','V_5','V_7','V_11','V_19',\\\n",
    "            'V_24', 'V_27', 'V_28', 'V_31', 'V_32',\\\n",
    "            'V_33', 'V_40', 'V_41', 'V_42', 'V_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_cols = list(set(df.columns) - set(continous_cols))\n",
    "cate_cols.sort(key = lambda x : int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cate_cols_v2 contains columns without pipes and 3 bad columns\n",
    "cate_cols_v2 = list(set(cate_cols) - set(pipe_col))\n",
    "cate_cols_v2.remove('V_35') # \"Right now, I can't stop listening to:\" - No fixed options\n",
    "cate_cols_v2.remove('V_36') # \"I live in:\" - Zipcode\n",
    "cate_cols_v2.remove('V_8') # \"I'm not working because:\" - null\n",
    "cate_cols_v2.sort(key = lambda x : int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of null value for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(columns=['Column','Desc', 'Null'])\n",
    "for col in df.columns:\n",
    "    num_null = df[col].isnull().sum()\n",
    "    dff = dff.append({'Column': col, 'Desc' : col_dict[col], 'Null' : num_null }, ignore_index=True)\n",
    "dff.sort_values(by = \"Null\", ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at Salary Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The 99% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 99))))\n",
    "\n",
    "print('The 90% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 90))))\n",
    "\n",
    "print('The 85% percentile of salary is: ' + \\\n",
    "      str(int(np.percentile(df.V_18.dropna(), 85))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a look at salary vs. age\n",
    "dff = pd.DataFrame()\n",
    "dff['salary'] = df['V_18'] / 1000\n",
    "dff['age'] = df['V_37']\n",
    "dff['salary over million'] = dff['salary'] > 1000\n",
    "sns.lmplot(data = dff, x = 'salary', y = 'age', fit_reg = False, hue = 'salary over million')\n",
    "plt.xlabel('Salary (thousand)')\n",
    "plt.ylabel('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export a separate file with salary over million record\n",
    "# df_with_column_names(df[df.V_18 > 1000000], col_dict).to_csv('output_salary_over_million.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break \"Age\" into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_break(x):\n",
    "    if (x < 20): return ('Younger than 20')\n",
    "    elif (x <= 25): return ('20 to 25')\n",
    "    elif (x <= 30): return ('25 to 30')\n",
    "    elif (x <= 35): return ('30 to 35')\n",
    "    elif (x <= 40): return ('35 to 40')\n",
    "    elif (x <= 45): return ('40 to 45')\n",
    "    elif (x <= 50): return ('45 to 50')\n",
    "    else: return ('Older than 50')\n",
    "\n",
    "df['V_37'] = df['V_37'].apply(lambda x : age_break(x))\n",
    "cate_cols.append('V_37')\n",
    "continous_cols.remove('V_37')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude outliers for salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Remove outliers for salary\n",
    "# 1. Null values \n",
    "# 2. zero salary\n",
    "# 3. Top 1% salary\n",
    "\n",
    "df = df[~((df.V_18.isnull()) | \n",
    "          (df.V_18 == 0) | \n",
    "          (df.V_18 > 210000))]\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Done for Jon to export raw data with and without salary outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "raw_df = pd.read_csv('DesignCensus2017_Data.csv')\n",
    "salary = raw_df['18 --My annual salary is:']\n",
    "raw_df_salary_outliers  = raw_df [((salary.isnull()) | (salary == 0) | (salary > 210000))]\n",
    "raw_df_excluding_outliers  = raw_df [~((salary.isnull()) | (salary == 0) | (salary > 210000))]\n",
    "raw_df_salary_outliers.to_csv('./export_csv/raw_data_salary_outliers.csv', index = False, encoding = 'utf8')\n",
    "raw_df_excluding_outliers.to_csv('./export_csv/raw_data_excluding_salary_outliers.csv', index = False, encoding = 'utf8')\n",
    "del raw_df, raw_df_salary_outliers, raw_df_excluding_outliers\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to deal with columns with pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.replace(np.nan,'', regex=True)\n",
    "pipe_col_dict = {}\n",
    "\n",
    "for col in pipe_col:\n",
    "    options = set()\n",
    "    for row in df[col]:\n",
    "        arrs = row.split('|') \n",
    "        for arr in arrs:\n",
    "            if arr != '':\n",
    "                options.add(arr)\n",
    "    \n",
    "    pipe_col_dict[col] = {}\n",
    "    \n",
    "    index = 1\n",
    "    for option in options:\n",
    "        sub_col = col + '_' + str(index)\n",
    "        df.loc[:,sub_col] = 0\n",
    "        pipe_col_dict[col][option] = sub_col\n",
    "        col_dict[sub_col] = col_dict[col] + '-' + option\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this part takes a few minutes to run\n",
    "for col in pipe_col:\n",
    "    row_num = 0;\n",
    "    for row in df[col]:\n",
    "        arrs = row.split('|') \n",
    "        for arr in arrs:\n",
    "            if arr != '':\n",
    "                sub_col = pipe_col_dict[col][arr]\n",
    "                df.loc[row_num, sub_col] += 1\n",
    "        row_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output csv w/ and w/o column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('./export_csv/processed_output_without_column_names.csv', index = False, encoding = 'utf8')\n",
    "df_with_column_names(df, col_dict).to_csv(\\\n",
    "    './export_csv/processed_output_with_column_names.csv', index = False, encoding = 'utf8')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export some important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('SavedVariables.pckl', 'wb') as f:\n",
    "    pickle.dump([continous_cols, cate_cols, cate_cols_v2, pipe_col, col_dict, pipe_col_dict], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<a id='2.0'></a>\n",
    "# Part II, Barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### Read in processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./export_csv/processed_output_without_column_names.csv', encoding = 'utf8')\n",
    "with open('SavedVariables.pckl', 'rb') as f:\n",
    "    continous_cols, cate_cols, cate_cols_v2, pipe_col, col_dict, pipe_col_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Summary of each column (only show `top k`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_cate_col(col, top_k, AllorAIGA = 'All'): #default is all records\n",
    "    \n",
    "    AIGA_col = pipe_col_dict['V_32']['AIGA']\n",
    "    if AllorAIGA == 'All':\n",
    "        df_filtered = df\n",
    "    else:\n",
    "        df_filtered = df[df[AIGA_col] == 1]\n",
    "        \n",
    "    if col in continous_cols:\n",
    "        return\n",
    "    \n",
    "    elif col in pipe_col:\n",
    "        dff = pd.DataFrame(columns=['Options','Count','Percent'])\n",
    "        for key, value in pipe_col_dict[col].items():\n",
    "            count = df_filtered[value].sum()\n",
    "            dff = dff.append({'Options': key, 'Count' : count}, ignore_index=True)\n",
    "    else:\n",
    "        dff = pd.DataFrame(df_filtered[col].value_counts())\n",
    "        dff.reset_index(inplace=True)\n",
    "        dff.columns = ['Options','Count']\n",
    "    \n",
    "    dff['Percent'] = dff.Count / len(df_filtered)\n",
    "    dff = dff.sort_values(by = 'Percent', ascending = False).head(top_k)\n",
    "    return dff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution (%) for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cate_cols:\n",
    "    if 'V_8' in col:\n",
    "        continue\n",
    "    if 'V_35' in col:\n",
    "        continue\n",
    "    if 'V_36' in col:\n",
    "        continue\n",
    "    display(str(col) + ' : ' + col_dict[col])\n",
    "    dff = summary_cate_col(col, 1000)\n",
    "    display_dff = dff.style.format({'Percent': '{:,.2%}'.format})\n",
    "    display(display_dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "### ** Add plots for each column (All or AIGA-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AIGA_col = pipe_col_dict['V_32']['AIGA']\n",
    "print('The total numeber of AIGA members is: ' + str(len(df[df[AIGA_col] == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_single_column(dff, AllorAIGA):\n",
    "    # plot bar plot for each option\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.set_context(\"notebook\", font_scale=1.5)\n",
    "    g = sns.barplot(y='Options', x = 'Count',data=dff, color = 'blue', ci = None)\n",
    "    max_count = max(dff['Count'])\n",
    "    plt.xlim(0, max_count * 1.5)  \n",
    "\n",
    "    # add labels\n",
    "    ax = plt.gca()\n",
    "    for p,count, percent in zip(ax.patches,dff['Count'],dff['Percent']):\n",
    "        \n",
    "        ax.annotate(str('{:,}'.format(count)) +' (' + str('{:,.0%}'.format(percent)) +')', \n",
    "                    (p.get_x() + p.get_width()+max_count/50 ,p.get_y()+p.get_height()/2 ),# location\n",
    "                    xytext=(0, 0), textcoords='offset points',# offset\n",
    "                    va=\"center\",ha=\"left\", size = 12, rotation=0) #text align and font size\n",
    "     \n",
    "    # add info and save\n",
    "    plt.title(AllorAIGA + '_Distribution of \"' + col_dict[col] + '\"')\n",
    "    plt.ylabel(col_dict[col])\n",
    "    plt.xlabel('Count')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('./fig/'+ AllorAIGA + '_Single_Column_' + str(col_dict[col]) + '_Plot.png',dpi=100,format='png')\n",
    "    plt.savefig('./svgfig/'+ AllorAIGA + '_Single_Column_' + str(col_dict[col]) + '_Plot.svg',dpi=100,format='svg')\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cate_cols:\n",
    "    if 'V_8' in col:\n",
    "        continue\n",
    "    if 'V_35' in col:\n",
    "        continue\n",
    "    if 'V_36' in col:\n",
    "        continue\n",
    "    \n",
    "    # get summary table each column (All)\n",
    "    dff = summary_cate_col(col, 1000, AllorAIGA = 'All')\n",
    "    plot_single_column(dff, AllorAIGA = 'All')\n",
    "    \n",
    "    # get summary table each column (AIGA-Only)\n",
    "    dff = summary_cate_col(col, 1000, AllorAIGA = 'AIGA-Only')\n",
    "    plot_single_column(dff, AllorAIGA = 'AIGA-Only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "### Plot `salary` vs. all columns (barplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All figs are saved under 'fig' folder\n",
    "sns.set_context(\"notebook\", font_scale=2)\n",
    "for col in cate_cols_v2:\n",
    "    groupedvalues = df.groupby(col, as_index = False).agg({'V_18': [np.mean, percentile(95), percentile(5),'count']})\n",
    "    groupedvalues.columns = [col, 'V_18_avg', 'V_18_max', 'V_18_min','V_18_count']\n",
    "    groupedvalues.sort_values(by = 'V_18_avg', inplace=True)\n",
    "    order = list(groupedvalues[col])\n",
    "    \n",
    "    plt.figure(figsize=(15,10))\n",
    "    colorPalette = sns.cubehelix_palette(len(order))\n",
    "    g=sns.barplot(x='V_18', y=col, data=df, estimator= np.mean, \\\n",
    "                order = order,  palette=colorPalette, ci = None)\n",
    "    plt.xlim(0,150000)\n",
    "    \n",
    "    # add data labels\n",
    "    ax = plt.gca()\n",
    "    for p,vmin,vavg,vmax,count in zip(ax.patches,groupedvalues['V_18_min'],groupedvalues['V_18_avg'],\n",
    "                                                 groupedvalues['V_18_max'],groupedvalues['V_18_count']):\n",
    "        ax.annotate('5%: ' + \"{0:n}\".format(int(vmin)) +  # value\n",
    "                    '\\nAvg: ' + \"{0:n}\".format(int(vavg)) +\n",
    "                    '\\n95%: ' + \"{0:n}\".format(int(vmax)) + \n",
    "                    '\\nCount: ' + \"{0:n}\".format(int(count)),\n",
    "                    (p.get_x() + p.get_width(),p.get_y()+0.5*p.get_height()),# location\n",
    "                    xytext=(5, 0), textcoords='offset points',# offset\n",
    "                    va=\"center\", size = 12) #text align and font size\n",
    "        \n",
    "    #plot axes and export\n",
    "    plt.xlabel('Salary')\n",
    "    plt.ylabel(col_dict[col])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./fig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.png',dpi=100)\n",
    "    plt.savefig('./svgfig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.svg',dpi=100, format='svg')\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. For columns with pipes\n",
    "dff = pd.DataFrame(columns = ['Col', 'Option', 'Salary'])\n",
    "for col in pipe_col:\n",
    "    for option, sub_col in pipe_col_dict[col].items():\n",
    "        salary_avg = df.loc[df[sub_col] == 1, 'V_18'].mean()\n",
    "        salary_min = np.percentile(df.loc[df[sub_col] == 1, 'V_18'],5)\n",
    "        salary_max = np.percentile(df.loc[df[sub_col] == 1, 'V_18'],95)\n",
    "        count = len(df.loc[df[sub_col] == 1, 'V_18'])\n",
    "        dff = dff.append({'Col': col, 'Option' : option, 'Salary_min' : salary_min,\n",
    "                          'Salary_avg' : salary_avg, 'Salary_max' : salary_max, 'Count' :count }, \\\n",
    "                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All figs are saved under 'fig' folder\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "for col in pipe_col:\n",
    "    dfff = dff[dff.Col == col].sort_values(by = 'Salary_avg')\n",
    "    order = list(dfff['Option'])\n",
    "    plt.figure(figsize=(15,10))\n",
    "    colorPalette = sns.cubehelix_palette(len(order), rot=-.75)\n",
    "    sns.barplot(x = 'Salary_avg', y = 'Option', data = dfff, estimator= np.mean, \\\n",
    "                order = order, palette=colorPalette)\n",
    "    plt.xlim(0, max(150000, max(dfff['Salary_avg']) + 120000)) \n",
    "    \n",
    "    # add data labels\n",
    "    ax = plt.gca()\n",
    "    for p,vmin,vavg,vmax,count in zip(ax.patches,dfff['Salary_min'], dfff['Salary_avg'],\n",
    "                                                 dfff['Salary_max'], dfff['Count']):\n",
    "        ax.annotate('5%: ' + \"{0:n}\".format(int(vmin)) +  # value\n",
    "                    '; Avg: ' + \"{0:n}\".format(int(vavg)) +\n",
    "                    '; 95%: ' + \"{0:n}\".format(int(vmax)) +\n",
    "                    '; Count: ' + \"{0:n}\".format(int(count)),\n",
    "                    (p.get_x() + p.get_width(),p.get_y()+0.5*p.get_height()),# location\n",
    "                    xytext=(5, 0), textcoords='offset points',# offset\n",
    "                    va=\"center\", size = 12) #text align and font size \n",
    "    #plot axes and export    \n",
    "    plt.xlabel('Salary')\n",
    "    plt.ylabel(col_dict[col])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./fig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.png',dpi=100)\n",
    "    plt.savefig('./svgfig/'+ 'Salary vs. ' + col_dict[col] + '_Plot.svg',dpi=100, format='svg')\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<a id='3.0'></a>\n",
    "# Part III, Heatmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "### Read in processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./export_csv/processed_output_without_column_names.csv', encoding = 'utf8')\n",
    "with open('SavedVariables.pckl', 'rb') as f:\n",
    "    continous_cols, cate_vols, cate_cols_v2, pipe_col, col_dict, pipe_col_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(raw_df, col_1, col_1_desc, col_2, col_2_desc, col_salary):\n",
    "    df = raw_df.copy()\n",
    "    sns.set(font_scale = 1)\n",
    "    df[col_salary] = df[col_salary].apply(lambda x : np.round_(x/1000))\n",
    "    pivot_table=pd.pivot_table(df, index=col_1, columns=col_2, \n",
    "                               values = col_salary, aggfunc=np.mean)\n",
    "    colorPalette = sns.cubehelix_palette()\n",
    "    sns.heatmap(pivot_table, annot=True, cmap=colorPalette)\n",
    "    plt.xlabel(col_2_desc)\n",
    "    plt.ylabel(col_1_desc)\n",
    "    plt.title('Average Salary Comparison (K)')\n",
    "    plt.savefig('./heatmaps/' + col_1_desc + ' vs. ' + col_2_desc + '.svg',format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Gender and Orientation Combo\n",
    "plot_heatmap(df[df['V_38'] != 'Other'], # exclude GENDER == 'Other'\n",
    "             'V_38', 'Gender', \n",
    "             'V_39', 'Orientation',\n",
    "             'V_18') #salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Process RACE and combine with GENDER, ORIENTATION (duplicate rows)\n",
    "hm_heat = pd.DataFrame(columns=['index','Gender', 'Orientation','Race', 'Salary'])# v38, v39, v40, v18\n",
    "for index, row in df.iterrows():\n",
    "    for option, subcol in pipe_col_dict['V_40'].items(): #race\n",
    "        if row[subcol] == 1:\n",
    "            hm_heat = hm_heat.append({'index': index,\n",
    "                                      'Gender': row['V_38'],  #gender\n",
    "                                      'Orientation': row['V_39'], #orientation\n",
    "                                      'Race': option, \n",
    "                                      'Salary': row['V_18']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Race and Gender Combo\n",
    "plot_heatmap(hm_heat[hm_heat['Gender'] != 'Other'], # exclude GENDER == 'Other'\n",
    "             'Race', 'Race',\n",
    "             'Gender', 'Gender', \n",
    "             'Salary') #salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Race and Orientation Combo\n",
    "plot_heatmap(hm_heat[hm_heat['Gender'] != 'Other'], # exclude GENDER == 'Other'\n",
    "             'Race', 'Race',\n",
    "             'Orientation', 'Orientation', \n",
    "             'Salary') #salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Gender and Education\n",
    "plot_heatmap(df[df['V_38'] != 'Other'], # exclude GENDER == 'Other'\n",
    "             'V_38', 'Gender', \n",
    "             'V_26', 'Higest Education',\n",
    "             'V_18') #salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Grouped boxplot\n",
    "sns.boxplot(x=\"V_18\", y=\"V_26\", hue='V_38', data=df[df['V_38'] != 'Other'], orient=\"h\", palette=\"Set2\")\n",
    "ax = sns.stripplot(x='V_18', y='V_26', data=df[df['V_38'] != 'Other'], color=\"black\", jitter=0.4, size=1)\n",
    "\n",
    "# TRY VIOLIN PLOT TO VISUALIZE DISTRIBUTION... NEXT\n",
    "\n",
    "# How can I include the number of observations that go into each of the bars?\n",
    "# Just the number of rows that were used for any calculations...\n",
    "\n",
    "plt.savefig('./boxplot/EducationAndGender_Salary.svg',format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Not used now) Generate one-hot coded columns for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cate_cols_v2:\n",
    "    df.replace(np.nan,'', regex=True, inplace=True)\n",
    "    label_encoder = LabelEncoder()\n",
    "    feature = label_encoder.fit_transform(df[col])\n",
    "    feature = feature.reshape(df.shape[0], 1)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    feature = onehot_encoder.fit_transform(feature)\n",
    "    for i in range(feature.shape[1]):\n",
    "        df[col + '-' + str(i + 1)] = np.array(np.matrix(feature).transpose())[i]\n",
    "        col_dict[col + '-' + str(i + 1)] = col_dict[col] + '-' + label_encoder.classes_[i]\n",
    "    df.drop(col, axis = 1, inplace = True)\n",
    "\n",
    "for col in pipe_col:\n",
    "    df.drop(col, axis = 1, inplace = True)\n",
    "\n",
    "for col in ['V_8', 'V_35', 'V_36']:\n",
    "    df.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output a csv with all columns converted to numeric\n",
    "df.to_csv('./export_csv/processed_output_all_numeric.csv', index = False, encoding='utf8')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
